"use strict";(self.webpackChunkhumanoid_robotics_book=self.webpackChunkhumanoid_robotics_book||[]).push([[36],{5724:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"module-3-isaac/rl","title":"Reinforcement Learning for Robotics with NVIDIA Isaac","description":"Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions in an environment to maximize a reward signal. RL is well-suited for robotics tasks, as it allows robots to learn complex behaviors through trial and error.","source":"@site/docs/module-3-isaac/rl.mdx","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/rl","permalink":"/Hackathon-Physical-AI-Humanoid-Book/docs/module-3-isaac/rl","draft":false,"unlisted":false,"editUrl":"https://github.com/lotusf980/Hackathon-Physical-AI-Humanoid-Book/edit/main/docs/module-3-isaac/rl.mdx","tags":[],"version":"current","frontMatter":{"title":"Reinforcement Learning for Robotics with NVIDIA Isaac"},"sidebar":"tutorialSidebar","previous":{"title":"VSLAM and Navigation with NVIDIA Isaac","permalink":"/Hackathon-Physical-AI-Humanoid-Book/docs/module-3-isaac/vslam"},"next":{"title":"The Sim-to-Real Pipeline","permalink":"/Hackathon-Physical-AI-Humanoid-Book/docs/module-3-isaac/sim2real"}}');var t=i(4848),a=i(8453);const r={title:"Reinforcement Learning for Robotics with NVIDIA Isaac"},s="Reinforcement Learning for Robotics with NVIDIA Isaac",c={},l=[{value:"Reinforcement Learning with Isaac Sim",id:"reinforcement-learning-with-isaac-sim",level:2},{value:"Key Components for RL in Isaac Sim",id:"key-components-for-rl-in-isaac-sim",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"reinforcement-learning-for-robotics-with-nvidia-isaac",children:"Reinforcement Learning for Robotics with NVIDIA Isaac"})}),"\n",(0,t.jsx)(n.p,{children:"Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions in an environment to maximize a reward signal. RL is well-suited for robotics tasks, as it allows robots to learn complex behaviors through trial and error."}),"\n",(0,t.jsx)(n.h2,{id:"reinforcement-learning-with-isaac-sim",children:"Reinforcement Learning with Isaac Sim"}),"\n",(0,t.jsx)(n.p,{children:"NVIDIA Isaac Sim provides a powerful platform for training RL agents for robotics. It allows you to create realistic simulation environments and train agents using a variety of RL algorithms."}),"\n",(0,t.jsx)(n.h2,{id:"key-components-for-rl-in-isaac-sim",children:"Key Components for RL in Isaac Sim"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Environment"}),": The simulated world in which the RL agent interacts. Isaac Sim provides tools for creating realistic and diverse environments."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Agent"}),": The robot or software entity that learns to make decisions. You can define the agent's actions, observations, and reward function."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RL Algorithm"}),": The algorithm used to train the agent. Isaac Sim supports various RL algorithms."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reward Function"}),": Defines the goal that the agent is trying to achieve. The reward function should be carefully designed to incentivize the desired behavior."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>s});var o=i(6540);const t={},a=o.createContext(t);function r(e){const n=o.useContext(a);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),o.createElement(a.Provider,{value:n},e.children)}}}]);