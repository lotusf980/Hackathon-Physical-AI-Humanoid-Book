"use strict";(self.webpackChunkhumanoid_robotics_book=self.webpackChunkhumanoid_robotics_book||[]).push([[501],{8453:(e,o,n)=>{n.d(o,{R:()=>r,x:()=>a});var i=n(6540);const t={},s=i.createContext(t);function r(e){const o=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(o):{...o,...e}},[o,e])}function a(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(s.Provider,{value:o},e.children)}},9055:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-4-vla/whisper","title":"Voice Recognition with Whisper","description":"Whisper is a neural network developed by OpenAI that transcribes spoken language into text. It is a powerful tool for enabling robots to understand and respond to human voice commands.","source":"@site/docs/module-4-vla/whisper.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/whisper","permalink":"/Hackathon-Physical-AI-Humanoid-Book/docs/module-4-vla/whisper","draft":false,"unlisted":false,"editUrl":"https://github.com/lotusf980/Hackathon-Physical-AI-Humanoid-Book/edit/main/docs/module-4-vla/whisper.mdx","tags":[],"version":"current","frontMatter":{"title":"Voice Recognition with Whisper"},"sidebar":"tutorialSidebar","previous":{"title":"Module 4: Vision-Language-Action","permalink":"/Hackathon-Physical-AI-Humanoid-Book/docs/module-4-vla/introduction"},"next":{"title":"LLM Planning for Robotics","permalink":"/Hackathon-Physical-AI-Humanoid-Book/docs/module-4-vla/llm_planning"}}');var t=n(4848),s=n(8453);const r={title:"Voice Recognition with Whisper"},a="Voice Recognition with Whisper",l={},c=[{value:"Key Features of Whisper",id:"key-features-of-whisper",level:2},{value:"Using Whisper for Robotics",id:"using-whisper-for-robotics",level:2},{value:"Code Example",id:"code-example",level:2}];function d(e){const o={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.header,{children:(0,t.jsx)(o.h1,{id:"voice-recognition-with-whisper",children:"Voice Recognition with Whisper"})}),"\n",(0,t.jsx)(o.p,{children:"Whisper is a neural network developed by OpenAI that transcribes spoken language into text. It is a powerful tool for enabling robots to understand and respond to human voice commands."}),"\n",(0,t.jsx)(o.h2,{id:"key-features-of-whisper",children:"Key Features of Whisper"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.strong,{children:"Multilingual"}),": Whisper supports transcription in multiple languages."]}),"\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.strong,{children:"Robustness"}),": Whisper is robust to noise and accents."]}),"\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.strong,{children:"Open Source"}),": Whisper is available as an open-source library."]}),"\n"]}),"\n",(0,t.jsx)(o.h2,{id:"using-whisper-for-robotics",children:"Using Whisper for Robotics"}),"\n",(0,t.jsx)(o.p,{children:"To use Whisper for robotics, you can use the Whisper API to transcribe audio data into text. You can then use natural language processing (NLP) techniques to extract the meaning of the text and use it to control the robot."}),"\n",(0,t.jsx)(o.h2,{id:"code-example",children:"Code Example"}),"\n",(0,t.jsx)(o.pre,{children:(0,t.jsx)(o.code,{className:"language-python",children:'import whisper\n\nmodel = whisper.load_model("base")\nresult = model.transcribe("audio.mp3")\nprint(result["text"])\n'})})]})}function u(e={}){const{wrapper:o}={...(0,s.R)(),...e.components};return o?(0,t.jsx)(o,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);